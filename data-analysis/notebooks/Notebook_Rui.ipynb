{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1_path = 'datasets/cleaned_100k.csv'\n",
    "data1 = pd.read_csv(file1_path, dtype={'WineID': str}, low_memory=False)\n",
    "\n",
    "file2_path = '/datasets/cleaned_ratings_file.csv'\n",
    "data2 = pd.read_csv(file2_path, dtype={'WineID': str}, low_memory=False)\n",
    "\n",
    "print(\"Columns in data1:\", data1.columns)\n",
    "print(\"Columns in data2:\", data2.columns)\n",
    "\n",
    "mean_ratings = data2.groupby('WineID')['Rating'].mean().reset_index()\n",
    "\n",
    "result = pd.merge(data1, mean_ratings, on='WineID', how='left')\n",
    "\n",
    "result.rename(columns={'Rating': 'Ratings'}, inplace=True)\n",
    "\n",
    "print(result.head())\n",
    "\n",
    "result.to_csv('updated_wines.csv', index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Data Preprocessing - Task [92]\n",
    "\n",
    "## Purpose\n",
    "\n",
    "1. Merging both updated_wines.csv that has the mean ratings, with the merged_wine_dataset that was the result of Report 2(id:65). Adding the rating of the first dataset to the second."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = \"datasets/updated_wines.csv\"\n",
    "file2 = \"datasets/merged_wine_dataset.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1) \n",
    "df2 = pd.read_csv(file2) \n",
    "\n",
    "# Merge the datasets based on WineName and WineryName\n",
    "merged_df = df2.merge(df1[['WineName', 'WineryName', 'Ratings']], on=['WineName', 'WineryName'], how='left')\n",
    "\n",
    "# Save the new dataset\n",
    "output_file = \"datasets/PLNTD_dataset.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"PLNTD_dataset created and saved to {output_file}\")\n",
    "\n",
    "missing_ratings = merged_df[merged_df['Ratings'].isna()]\n",
    "\n",
    "#Testing purposes\n",
    "if not missing_ratings.empty:\n",
    "    print(\"WARNING: Some rows in the dataset are missing a rating.\")\n",
    "    print(missing_ratings)\n",
    "else:\n",
    "    print(\"SUCCESS: All rows have a rating.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Data Preprocessing - Task [002]\n",
    "\n",
    "## Purpose\n",
    "\n",
    "1. Splitting text components for better granularity.\n",
    "2. Normalizing numerical values to ensure consistency.\n",
    "3. Removing unnecessary symbols or irrelevant text.\n",
    "\n",
    "The preprocessing will address these specific attributes in the dataset:\n",
    "- **Style**\n",
    "- **Characteristics**\n",
    "- **Price**\n",
    "- **Capacity**\n",
    "- **ABV (Alcohol by Volume)**\n",
    "- **Vintage**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'datasets/WineDataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def convert_to_liters(capacity):\n",
    "    capacity = str(capacity).strip().upper()\n",
    "    if 'CL' in capacity:  # Centiliters to Liters\n",
    "        return float(re.sub(r'[^\\d.]', '', capacity)) / 100\n",
    "    elif 'ML' in capacity:  # Milliliters to Liters\n",
    "        return float(re.sub(r'[^\\d.]', '', capacity)) / 1000\n",
    "    elif 'LITRE' in capacity or 'L' in capacity:  # Liters already\n",
    "        return float(re.sub(r'[^\\d.]', '', capacity))\n",
    "    elif 'LTR' in capacity or 'L' in capacity:  # Liters already\n",
    "        return float(re.sub(r'[^\\d.]', '', capacity))\n",
    "    elif 'L' in capacity or 'L' in capacity:  # Liters already\n",
    "        return float(re.sub(r'[^\\d.]', '', capacity))\n",
    "    else:\n",
    "        return ''  # Handle any unknown format\n",
    "\n",
    "def preprocess_data(df):\n",
    "\n",
    "    numeric_cols = ['Price', 'ABV', 'Capacity']\n",
    "\n",
    "    df['Capacity'] = df['Capacity'].apply(convert_to_liters)\n",
    "\n",
    "    if not df.empty:\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                # Remove non-numeric characters and convert to float\n",
    "                df[col] = df[col].apply(lambda x: re.sub(r'[^\\d.]', '', str(x)).strip() if str(x).strip() else np.nan)\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                if df[col].notnull().any():  # Check if there's valid data for scaling\n",
    "                    scaler = MinMaxScaler()\n",
    "                    df[col] = scaler.fit_transform(df[[col]])\n",
    "                \n",
    "                df[col] = df[col].round(3)\n",
    "\n",
    "        # Clean and split the 'Style' column\n",
    "        if 'Style' in df.columns:\n",
    "            df['Style'] = (\n",
    "                df['Style']\n",
    "                .str.replace(r'[^\\w\\s&]', '', regex=True)\n",
    "                .str.split('&')\n",
    "                .apply(lambda x: [item.strip() for item in x] if isinstance(x, list) else x)  # Clean whitespace\n",
    "            )\n",
    "\n",
    "            # This code divides the 'Style' array into several columns, each representing a position in that array\n",
    "            max_len = df['Style'].apply(lambda x: len(x) if isinstance(x, list) else 0).max()\n",
    "\n",
    "            for i in range(1, max_len + 1):\n",
    "                df[f'Style {i}'] = df['Style'].apply(lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else '')\n",
    "\n",
    "            df = df.drop(columns=['Style'])\n",
    "\n",
    "        # Clean and split the 'Characteristics' column\n",
    "        if 'Characteristics' in df.columns:\n",
    "            df['Characteristics'] = (\n",
    "                df['Characteristics']\n",
    "                .str.replace(r'[^\\w\\s,]', '', regex=True)\n",
    "                .str.split(',') \n",
    "                .apply(lambda x: [item.strip() for item in x] if isinstance(x, list) else x)  # Clean whitespace\n",
    "            )\n",
    "            \n",
    "            # This code divides the 'Characteristics' array into several columns, each representing a position in that array\n",
    "            max_len = df['Characteristics'].apply(lambda x: len(x) if isinstance(x, list) else 0).max()\n",
    "\n",
    "            for i in range(1, max_len + 1):\n",
    "                df[f'Characteristic {i}'] = df['Characteristics'].apply(lambda x: x[i-1] if isinstance(x, list) and len(x) >= i else '')\n",
    "\n",
    "            df = df.drop(columns=['Characteristics'])\n",
    "            \n",
    "        # Clean and normalize the 'Vintage' column\n",
    "        if 'Vintage' in df.columns:\n",
    "            current_year = datetime.datetime.now().year\n",
    "\n",
    "            df['Vintage'] = df['Vintage'].apply(\n",
    "                lambda x: current_year if str(x).strip().upper() == 'NV' else (int(re.search(r'\\d{4}', str(x)).group(0)) if re.search(r'\\d{4}', str(x)) else np.nan)\n",
    "            )\n",
    "\n",
    "            valid_years = df['Vintage'][df['Vintage'] > 1900]\n",
    "            if not valid_years.empty:\n",
    "\n",
    "                min_year = valid_years.min()  \n",
    "                max_year = current_year\n",
    "\n",
    "                # Calculates the vintage value based on the max vintage and the current year\n",
    "                df['Vintage'] = df['Vintage'].apply(\n",
    "                    lambda x: max(0, (x - max_year) / (min_year - max_year)) if pd.notna(x) else np.nan\n",
    "                )\n",
    "\n",
    "                # Round the 'Vintage' values to 2 decimal places\n",
    "                df['Vintage'] = df['Vintage'].round(2)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocess the dataset\n",
    "df_cleaned = preprocess_data(df)\n",
    "\n",
    "# Save or display the cleaned dataset\n",
    "df_cleaned.to_csv('datasets/cleaned_wines.csv', index=False)\n",
    "df_cleaned.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'datasets/cleaned_wines.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get unique values in the 'Capacity' column\n",
    "unique_values = df['Capacity'].dropna().unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_values)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "file2_path = '/datasets/XWines_Full_100k_wines.csv'\n",
    "\n",
    "data2 = pd.read_csv(file2_path)\n",
    "\n",
    "data2['WineID'] = pd.to_numeric(data2['WineID'], errors='coerce')\n",
    "\n",
    "cleaned_data2 = data2.dropna(subset=['WineID'])\n",
    "\n",
    "cleaned_file_path = 'cleaned_100k.csv'\n",
    "cleaned_data2.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(cleaned_data2.head())\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "file2_path = '/datasets/updated_wines.csv'\n",
    "data2 = pd.read_csv(file2_path, dtype={'WineID': str}, low_memory=False)\n",
    "\n",
    "invalid_rows = data2[pd.to_numeric(data2['Ratings'], errors='coerce').isna()]\n",
    "\n",
    "print(\"Rows with invalid or empty 'Ratings':\")\n",
    "print(invalid_rows)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "file2_path = 'datasets/updated_wines.csv'\n",
    "\n",
    "data2 = pd.read_csv(file2_path, dtype={'WineID': str}, low_memory=False)\n",
    "\n",
    "data2['Ratings'] = pd.to_numeric(data2['Ratings'], errors='coerce')\n",
    "\n",
    "data2['Ratings'] = data2['Ratings'].apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\")\n",
    "\n",
    "data2.to_csv(file2_path, index=False)\n",
    "\n",
    "print(f\"Ratings formatted to two decimal places. The original file has been updated: {file2_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
