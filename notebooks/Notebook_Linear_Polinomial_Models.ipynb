{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) \n",
    "\n",
    "First, the data was loaded from a CSV file. For the analysis and processing of this data, the wine dataset was cleaned, and finally, we proceeded with visualization and outlier detection. The data was normalized using encoders.\n",
    "\n",
    "For data cleaning, the text in categorical columns was corrected to fix encoding errors, and the relevant columns—Type, Grape, and Price—were selected. The Price column was cleaned by removing non-numeric characters and converting the values to float type. Rows with missing values in the selected columns were also removed.\n",
    "\n",
    "The encoders used were One-hot for the Type column and Binary for the Grape column. The encoded data was combined into a new DataFrame. The Price column was scaled using MinMaxScaler to normalize the data between 0 and 1.\n",
    "\n",
    "For data visualization, distribution plots (histplots) of the predictive variable Price were created, a countplot was used to visualize the distribution of wine types, and a correlation matrix with its corresponding heatmap was generated to observe relationships between variables.\n",
    "\n",
    "To detect outliers, the interquartile range (IQR) was calculated to identify outliers in the Price column, and these outliers were visualized using a boxplot. Due to the nature of the data and its fidelity to the market reality, the outliers were not removed.\n",
    "\n",
    "The main insights from the EDA are as follows:\n",
    "\n",
    "- Q1 ($12.99): 25% of prices are below this\n",
    "- Q3 ($29.99): 75% of prices are below this\n",
    "- IQR ($17.00): Range containing middle 50% of prices (Q3-Q1)\n",
    "- Red and White types are the clear market leaders, each with almost 550 units\n",
    "- Weak correlation between Price and Type, Grape\n",
    "- From PCA, we can see that the data is not linearly separable\n",
    "- The Price distribution is right-skewed, with a long tail of high prices, which means that the data is not normally distributed and the closest model to follow the data distribution is a polinomial regression model \n",
    "- The Types Orange and Tawny does not have a significant number of samples, which can lead to a bias in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import (OneHotEncoder, MinMaxScaler, \n",
    "                                   StandardScaler, PolynomialFeatures)\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet, \n",
    "                                  SGDRegressor)\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Metrics and Model/Data Selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Feature engineering\n",
    "import category_encoders as ce\n",
    "from ftfy import fix_text\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn and Matplotlib configurations for modern aesthetics\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../datasets/WineDataset.csv')\n",
    "\n",
    "# Continue with your cleaning steps...\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object': \n",
    "        df[col] = df[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Print after cleaning to verify data still exists\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"Number of rows:\", len(df))\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['Type', 'Grape', 'Price']]\n",
    "\n",
    "# Clean the 'Price' column by extracting numerical values\n",
    "df['Price'] = df['Price'].str.replace('£', '', regex=False)        \n",
    "df['Price'] = df['Price'].str.replace('per bottle', '', regex=False) \n",
    "\n",
    "# Remover espaços extras e converter para float\n",
    "df['Price'] = df['Price'].str.strip()\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing or invalid prices\n",
    "df = df.dropna(subset=['Price'])\n",
    "\n",
    "# Drop rows with missing values in categorical columns\n",
    "df = df.dropna(subset=['Type', 'Grape'])\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "type_encoded = pd.DataFrame(one_hot_encoder.fit_transform(df[['Type']]), columns=one_hot_encoder.get_feature_names_out(['Type']))\n",
    "\n",
    "# Initialize the binary encoder\n",
    "binary_encoder = ce.BinaryEncoder(cols=['Grape'])\n",
    "\n",
    "# Apply the encoder to the 'Grape' column\n",
    "grape_encoded = binary_encoder.fit_transform(df['Grape'])\n",
    "\n",
    "# Combine all encoded data into a single dataframe\n",
    "df_encoded = pd.concat([df[['Price']], type_encoded, grape_encoded], axis=1)\n",
    "df_encoded = df_encoded.dropna()  # Assign the result back\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_encoded['Price'] = scaler.fit_transform(df_encoded[['Price']])\n",
    "\n",
    "print(df_encoded)\n",
    "\n",
    "# Plot distribution of Price\n",
    "sns.histplot(df['Price'], kde=True, bins=30, color='blue')\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Type Distribution\n",
    "sns.countplot(x='Type', data=df, palette='cool')\n",
    "plt.title('Type Distribution')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix Visualization\n",
    "correlation_matrix = df_encoded.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detecting Outliers using Boxplot\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = df['Price'].quantile(0.25)\n",
    "Q3 = df['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate whisker boundaries\n",
    "whisker_min = Q1 - 1.5 * IQR \n",
    "whisker_max = Q3 + 1.5 * IQR\n",
    "\n",
    "# Print IQR statistics\n",
    "print(f'Q1: {Q1}')\n",
    "print(f'Q3: {Q3}')\n",
    "print(f'IQR: {IQR}')\n",
    "print(f'Lower whisker: {whisker_min}')\n",
    "print(f'Upper whisker: {whisker_max}')\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "max_price = df['Price'].max()\n",
    "plt.xticks(np.arange(0, max_price + 50, 50))  \n",
    "sns.boxplot(x=df['Price'], color='red')\n",
    "plt.title('Outliers in Price')\n",
    "plt.xlabel('Price')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis\n",
    "\n",
    "We use PCA in order to perform dimensionality reduction, by reducing the complexity of the data  into a 2D space we can visualize high-dimensional data to understand the relationships between features and the target variable, Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['Price'] = df['Price']\n",
    "\n",
    "df_encoded_clean = df_encoded.dropna()\n",
    "features = df_encoded_clean.drop(columns=['Price']).values\n",
    "labels = df_encoded_clean['Price'].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(features)\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "step = 10\n",
    "\n",
    "for i in range(0, len(unique_labels), step):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    subset_labels = unique_labels[i:i + step]\n",
    "    \n",
    "    for label in subset_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        plt.scatter(\n",
    "            df_pca[indices, 0],\n",
    "            df_pca[indices, 1],\n",
    "            label=f'Price: {label:.4f}'\n",
    "        )\n",
    "    \n",
    "    plt.title('PCA (2D) - Coloreado por Precio')\n",
    "    plt.xlabel('Componente Principal 1')\n",
    "    plt.ylabel('Componente Principal 2')\n",
    "    plt.legend(title='Rango de Precios', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the binary encoder\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Drop rows with Grape 'Orange' and 'Tawny'\n",
    "values = ['Tawny', 'Orange']\n",
    "df_copy = df_copy[~df_copy['Type'].isin(values)]\n",
    "\n",
    "# Apply the encoder to the 'Grape' column\n",
    "type_encoded = pd.DataFrame(one_hot_encoder.fit_transform(df_copy[['Type']]), columns=one_hot_encoder.get_feature_names_out(['Type']))\n",
    "\n",
    "# Combine all encoded data into a single dataframe\n",
    "df_encoded = pd.concat([df[['Price']], type_encoded, grape_encoded], axis=1)\n",
    "df_encoded = df_encoded.dropna()  # Assign the result back\n",
    "\n",
    "# Combine all encoded data into a single dataframe\n",
    "df_encoded = pd.concat([df[['Price']], type_encoded, grape_encoded], axis=1)\n",
    "df_encoded = df_encoded.dropna()  # Assign the result back\n",
    "\n",
    "\n",
    "print(df_encoded)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X = df_encoded.drop(columns=['Price'])\n",
    "y = df_encoded['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Polynomial Regression Price not Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y_train)\n",
    "\n",
    "# Print metrics\n",
    "print('R² score:', model.score(X_poly_test, y_test))\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "\n",
    "# Predict prices\n",
    "y_pred = model.predict(X_poly_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Regression Price not Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print metrics\n",
    "print('R² score:', model.score(X_test, y_test))\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "\n",
    "# MAE (Mean Absolute Error), MSE (Mean Squared Error) and RMSE (Root Mean Squared Error) metrics\n",
    "\n",
    "\n",
    "# Predict prices\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Polynomial Regression Model Price Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression with scaled features\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_scaled, y_train)\n",
    "\n",
    "# Polynomial Regression with scaled features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "X_poly_test = poly.transform(X_scaled_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, y_train)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Linear Regression Results:\")\n",
    "print('R² score:', linear_model.score(X_scaled_test, y_test))\n",
    "print('Coefficients:', linear_model.coef_)\n",
    "print('Intercept:', linear_model.intercept_)\n",
    "\n",
    "print(\"\\nPolynomial Regression Results:\")\n",
    "print('R² score:', poly_model.score(X_poly_test, y_test))\n",
    "print('Coefficients:', poly_model.coef_)\n",
    "print('Intercept:', poly_model.intercept_)\n",
    "\n",
    "# Predict prices\n",
    "y_pred = linear_model.predict(X_test)\n",
    "y_pred_poly = poly_model.predict(X_poly_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('\\nLinear Regression Metrics:')\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "# Calculate metrics for polynomial regression\n",
    "mae = mean_absolute_error(y_test, y_pred_poly)\n",
    "mse = mean_squared_error(y_test, y_pred_poly)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('\\nPolynomial Regression Metrics:')\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model Price Encoded and with Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with log transformation of price\n",
    "X = df_encoded.drop('Price', axis=1).values\n",
    "y = np.log1p(df_encoded['Price'].values)  # log1p handles zero values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_scaled, y_train)\n",
    "\n",
    "# Predictions (need to transform back)\n",
    "y_pred = np.expm1(model.predict(X_scaled_test))\n",
    "\n",
    "# Print metrics\n",
    "print('R² score:', model.score(X_scaled_test, y_test))\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression Model Price Encoded and with Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "X_poly_test = poly.transform(X_scaled_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y_train)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_poly_test))\n",
    "\n",
    "print('R² score:', model.score(X_poly_test, y_test))\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df_encoded.drop('Price', axis=1).values\n",
    "y = np.log1p(df_encoded['Price'].values)\n",
    "\n",
    "# Ridge Regression with CV\n",
    "ridge_pipe = Pipeline([\n",
    "   ('scaler', StandardScaler()),\n",
    "   ('poly', PolynomialFeatures(degree=2)),\n",
    "   ('ridge', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "ridge_scores = cross_val_score(ridge_pipe, X, y, cv=5)\n",
    "print(\"Ridge CV scores:\", ridge_scores)\n",
    "print(\"Ridge mean CV score:\", ridge_scores.mean())\n",
    "\n",
    "# Lasso Regression with CV\n",
    "lasso_pipe = Pipeline([\n",
    "   ('scaler', StandardScaler()),\n",
    "   ('poly', PolynomialFeatures(degree=2)),\n",
    "   ('lasso', Lasso(alpha=1.0))\n",
    "])\n",
    "\n",
    "lasso_scores = cross_val_score(lasso_pipe, X, y, cv=5)\n",
    "print(\"\\nLasso CV scores:\", lasso_scores)\n",
    "print(\"Lasso mean CV score:\", lasso_scores.mean())\n",
    "\n",
    "# ElasticNet with CV\n",
    "elastic_pipe = Pipeline([\n",
    "   ('scaler', StandardScaler()),\n",
    "   ('poly', PolynomialFeatures(degree=2)),\n",
    "   ('elastic', ElasticNet(alpha=1.0, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "elastic_scores = cross_val_score(elastic_pipe, X, y, cv=5)\n",
    "print(\"\\nElasticNet CV scores:\", elastic_scores)\n",
    "print(\"ElasticNet mean CV score:\", elastic_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polinomial e Linear Regression Model Price Encoded and with Log transformation and Price Categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Price' to categorical with every 10 pounds as a category\n",
    "df_encoded['Price'] = np.ceil(df['Price'] / 20).astype(int)\n",
    "df_encoded['Price'] = df_encoded['Price'].dropna()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "df_encoded['Price'] = scaler.fit_transform(df_encoded[['Price']])\n",
    "\n",
    "print(df_encoded['Price'])\n",
    "\n",
    "# max and min values of 'Price' and the number of unique values and mean value and standard deviation and more common value\n",
    "\n",
    "print('Max:', df_encoded['Price'].max())\n",
    "print('Min:', df_encoded['Price'].min())\n",
    "print('Unique:', df_encoded['Price'].nunique())\n",
    "print('Mean:', df_encoded['Price'].mean())\n",
    "print('Std:', df_encoded['Price'].std())\n",
    "print('Most common:', df_encoded['Price'].mode().values[0])\n",
    "\n",
    "X = df_encoded.drop(columns=['Price'])\n",
    "y = df_encoded['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "X_poly_test = poly.transform(X_scaled_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y_train)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_poly_test))\n",
    "\n",
    "print('R² score:', model.score(X_poly_test, y_test))\n",
    "\n",
    "# Predict prices\n",
    "y_pred = model.predict(X_poly_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Logistic Regression\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, learning_rate='optimal')\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_pred = sgd_reg.predict(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "\n",
    "print('R² score:', sgd_reg.score(X_test, y_test))\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Polynomial Regression Model Normalized Price with Log Transformation Removing Price Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with price greater than 90\n",
    "\n",
    "df_copy = df_copy[df_copy['Price'] <= 40]\n",
    "\n",
    "df_encoded = pd.concat([df_copy[['Price']], type_encoded, grape_encoded], axis=1)\n",
    "df_encoded = df_encoded.dropna()  # Assign the result back\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_encoded['Price'] = scaler.fit_transform(df_encoded[['Price']])\n",
    "\n",
    "X = df_encoded.drop(columns=['Price'])\n",
    "y = df_encoded['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "X_poly_test = poly.transform(X_scaled_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y_train)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_poly_test))\n",
    "\n",
    "print('R² score:', model.score(X_poly_test, y_test))\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print('MAE:', mae)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
