{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização dataset - Task [001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ftfy import fix_text\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv file with pandas and read it into a dataframe\n",
    "df = pd.read_csv('../datasets/WineDataset.csv')\n",
    "df2 = pd.read_csv('../datasets/XWines_Full_100K_wines.csv')\n",
    "df3 = pd.read_csv('../datasets/merged_wine_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the information about the dataframe\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the information about the dataframe\n",
    "df2.info()\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the information about the dataframe\n",
    "df3.info()\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix text using ftfy\n",
    "# fix all the columns except when the column is a float\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object': \n",
    "        df[col] = df[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "# fix text using ftfy\n",
    "# fix all the columns except when the column is a float\n",
    "for col in df2.columns:\n",
    "    if df2[col].dtype == 'object': \n",
    "        df2[col] = df2[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all the unique values for each column except for the columns:'Title' 'Description', 'Country', 'Unit' 'Region' 'Appellation'\n",
    "for col in df.columns:\n",
    "    if col not in ['Title', 'Description', 'Country', 'Unit', 'Region', 'Appellation']:\n",
    "        print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df3.columns:\n",
    "    if col not in ['WineName', 'WineryName', 'Grape', 'Secondary Grape Varieties', 'Country', 'Region', 'Appellation', 'Style', 'Characteristics', 'Description']:\n",
    "        print(col, df3[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de dados\n",
    "- Remoção de valores nulos\n",
    "- Normalização de valores\n",
    "- Remoção de colunas desnecessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print wine where wineid 131027\n",
    "print(df2.loc[df2['WineID'] == 131027])\n",
    "\n",
    "#One-Hot Encoding for the column 'Type' 'Elaborate' 'Body', 'Acidity'\n",
    "\n",
    "one_hot_encoded_df = pd.get_dummies(df2, columns=['Type','Body','Acidity','Elaborate'], prefix=['Type','Body','Acidity','Elaborate'])\n",
    "\n",
    "# Binary Encoding for the column 'Country', 'RegionName', 'Grapes', 'Harmonize'\n",
    "\n",
    "encoder = BinaryEncoder(cols=['Grapes', 'Harmonize'], return_df=True)\n",
    "binary_encoded_df = encoder.fit_transform(df2)\n",
    "\n",
    "encoded_df = pd.concat([one_hot_encoded_df, binary_encoded_df], axis=1)\n",
    "\n",
    "# Normalize the 'ABV' column using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing the 'ABV' column\n",
    "encoded_df['ABV'] = scaler.fit_transform(encoded_df[['ABV']])\n",
    "\n",
    "\n",
    "encoded_df = encoded_df.drop(columns=df2.columns)\t\n",
    "encoded_df = encoded_df.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Dataset Preprocessing - Task [066]\n",
    "### Normalizing Harmonize and grouping it into broader categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dishes with their broader categories in the Harmonize column\n",
    "df2['Harmonize'] = df2['Harmonize'].apply(eval)\n",
    "dish_to_category = {\n",
    "    'Beef': 'Meat', 'Lamb': 'Meat', 'Pork': 'Meat', 'Veal': 'Meat', 'Game Meat': 'Meat',\n",
    "    'Duck': 'Meat', 'Ham': 'Meat', 'Cold Cuts': 'Meat', 'Cured Meat': 'Meat',\n",
    "    'Poultry': 'Poultry', 'Chicken': 'Poultry',\n",
    "    'Rich Fish': 'Fish & Seafood', 'Lean Fish': 'Fish & Seafood', 'Shellfish': 'Fish & Seafood',\n",
    "    'Seafood': 'Fish & Seafood', 'Sushi': 'Fish & Seafood', 'Sashimi': 'Fish & Seafood',\n",
    "    'Codfish': 'Fish & Seafood', 'Fish': 'Fish & Seafood', 'Grilled': 'Fish & Seafood',\n",
    "    'Soft Cheese': 'Cheese', 'Hard Cheese': 'Cheese', 'Blue Cheese': 'Cheese',\n",
    "    'Maturated Cheese': 'Cheese', 'Goat Cheese': 'Cheese', 'Mild Cheese': 'Cheese',\n",
    "    'Medium-cured Cheese': 'Cheese', 'Cheese': 'Cheese',\n",
    "    'Pasta': 'Pasta', 'Tagliatelle': 'Pasta', 'Lasagna': 'Pasta',\n",
    "    'Paella': 'Fish & Seafood', 'Pizza' : 'Pasta',\n",
    "    'Vegetarian': 'Vegetarian & Vegan', 'Mushrooms': 'Vegetarian & Vegan', 'Salad': 'Vegetarian & Vegan',\n",
    "    'Fruit': 'Vegetarian & Vegan', 'Tomato Dishes': 'Vegetarian & Vegan', 'Beans': 'Vegetarian & Vegan',\n",
    "    'Eggplant Parmigiana': 'Vegetarian & Vegan', 'Light Stews': 'Vegetarian & Vegan',\n",
    "    'Appetizer': 'Appetizers & Snacks', 'Snack': 'Appetizers & Snacks',\n",
    "    'Aperitif': 'Appetizers & Snacks', 'French Fries': 'Appetizers & Snacks', 'Baked Potato': 'Appetizers & Snacks',\n",
    "    'Cream': 'Appetizers & Snacks',\n",
    "    'Sweet Dessert': 'Desserts', 'Fruit Dessert': 'Desserts', 'Citric Dessert': 'Desserts',\n",
    "    'Cake': 'Desserts', 'Chocolate': 'Desserts', 'Cookies': 'Desserts',\n",
    "    'Chestnut': 'Desserts', 'Spiced Fruit Cake': 'Desserts', 'Dessert': 'Desserts',\n",
    "    'Soufflé': 'Desserts', 'Dried Fruits': 'Desserts',\n",
    "    'Spicy Food': 'Spicy Food', 'Curry Chicken': 'Spicy Food', 'Asian Food': 'Spicy Food', 'Yakissoba': 'Spicy Food',\n",
    "    'Barbecue': 'Meat', 'Roast': 'Meat'\n",
    "}\n",
    "\n",
    "columns = df2.columns\n",
    "new_harmonize = df2.copy()\n",
    "new_harmonize['Harmonize'] = df2['Harmonize'].apply(lambda x: list(set(dish_to_category.get(dish, dish) for dish in x)))\n",
    "\n",
    "# Expand the Harmonize column into multiple rows, one for each dish\n",
    "new_harmonize = new_harmonize.explode('Harmonize')\n",
    "\n",
    "# Reset the index for consistency and remove any rows with 'Risotto' because it has a number of insignificant occurrences\n",
    "new_harmonize.reset_index(drop=True, inplace=True)\n",
    "new_harmonize = new_harmonize[new_harmonize['Harmonize'].apply(lambda x: 'Risotto' not in x)]\n",
    "df2 = new_harmonize.copy()\n",
    "\n",
    "# Get the unique dishes\n",
    "unique_categories = df2['Harmonize'].unique()\n",
    "\n",
    "# One-hot encoding\n",
    "for dish in unique_categories:\n",
    "    new_harmonize[f'Harmonize_{dish}'] = new_harmonize['Harmonize'].apply(lambda x: x == dish)\n",
    "# Turn new_harmonize into a harmonize dataframe\n",
    "new_harmonize = new_harmonize.drop(columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding for the column 'Type' 'Elaborate' 'Body', 'Acidity'\n",
    "one_hot_encoded_df = pd.get_dummies(df2, columns=['Type', 'Elaborate', 'Body', 'Acidity'])\n",
    "\n",
    "# Binary Encoding for the column 'Grapes'\n",
    "encoder = BinaryEncoder(cols=['Grapes'], return_df=True)\n",
    "binary_encoded_df = encoder.fit_transform(df2)\n",
    "\n",
    "encoded_df = one_hot_encoded_df.copy()\n",
    "\n",
    "# Maximum ABV value\n",
    "print(encoded_df['ABV'].min())\n",
    "print(encoded_df['ABV'].max())\n",
    "\n",
    "# get the row where the abv is min\n",
    "print(encoded_df[encoded_df['ABV'] == encoded_df['ABV'].min()])\n",
    "\n",
    "\n",
    "# Normalizing the 'ABV' column\n",
    "scaler = MinMaxScaler()\n",
    "encoded_df['ABV'] = scaler.fit_transform(encoded_df[['ABV']])\n",
    "\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "encoded_df = encoded_df.drop(columns=['Country', 'RegionName', 'Code', 'WineName', 'WineID', 'Vintages', 'Website', 'WineryID', 'WineryName', 'RegionID','Grapes','Harmonize'])\n",
    "encoded_df = encoded_df.dropna()\n",
    "# add new_harmonize to the encoded_df\n",
    "encoded_df = pd.concat([encoded_df, new_harmonize], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR\n",
    "numeric_df = encoded_df['ABV']\n",
    "q1 = numeric_df.quantile(0.25)\n",
    "q3 = numeric_df.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=numeric_df, showmeans=True, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the resulting boxplot, we observe that some values fall outside the ranges but are still relevant, as 0% alcohol wines, including dealcoholized varieties, remain within the wine category. These options retain the essence of traditional wines without alcohol. Additionally, beverages like firewater, with higher alcohol content, can also bring value to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix without the Elaborate columns to reduce the size of the heatmap\n",
    "elaborate_columns = encoded_df.columns[encoded_df.columns.str.startswith('Elaborate_')]\n",
    "matrix_df = encoded_df.drop(columns=elaborate_columns)\n",
    "correlation_matrix = matrix_df.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True, \n",
    "    fmt=\".2f\", \n",
    "    cmap=\"coolwarm\", \n",
    "    cbar=True, \n",
    "    annot_kws={\"size\": 10}\n",
    ")\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the matrix, we observe that it is relatively ‘cold,’ meaning it exhibits a low correlation index overall. Despite the generally low correlations between features, certain specific relationships do stand out. For instance, some dishes in the ‘Harmonize’ category show a notable correlation with particular wines, while certain body characteristics correlate with the alcohol by volume (ABV) and wine types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "harmonize_columns = [col for col in encoded_df.columns if col.startswith('Harmonize_')]\n",
    "\n",
    "# Loop through each 'harmonize_' column and perform PCA\n",
    "for label_col in harmonize_columns:\n",
    "    print(f\"Generating PCA plot for label column: {label_col}\")\n",
    "\n",
    "    features = encoded_df.drop(columns=[label_col])\n",
    "    labels = encoded_df[label_col].values\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    df_pca = pca.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_labels = np.unique(labels)\n",
    "    for label in unique_labels:\n",
    "        plt.scatter(\n",
    "            df_pca[labels == label, 0], \n",
    "            df_pca[labels == label, 1], \n",
    "            label=f'Classe {label}'\n",
    "        )\n",
    "\n",
    "    plt.title(f'PCA - Column: {label_col}')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying PCA to identify patterns and relationships among the different categories in the ‘Harmonize’ column, we encountered inconclusive results. The resulting plots showed the various categories exhibiting similar patterns, with data points widely scattered across the graphical space rather than concentrated in specific zones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🍷 Wine Type Prediction using Random Forest Classifier: Model Performance & Results - Task [089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     31066\n",
      "        True       1.00      1.00      1.00     24563\n",
      "\n",
      "    accuracy                           1.00     55629\n",
      "   macro avg       1.00      1.00      1.00     55629\n",
      "weighted avg       1.00      1.00      1.00     55629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assume 'encoded_df' is the DataFrame after preprocessing\n",
    "\n",
    "# Step 1: Define the target variable and feature columns\n",
    "target_column = 'Type_Red'  # Wine Type - Red (binary classification)\n",
    "\n",
    "# Selecting features (all columns except the target column)\n",
    "features = encoded_df.drop(columns=[target_column])  # Dropping the target column\n",
    "target = encoded_df[target_column]  # The target variable is 'Type_Red'\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Data preprocessing (handling categorical and numerical features)\n",
    "# One-hot encoding for categorical columns, standard scaling for numerical columns\n",
    "categorical_columns = features.select_dtypes(include=['object']).columns\n",
    "numerical_columns = features.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Step 4: Create a Random Forest pipeline (combine preprocessor with model)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The Random Forest Classifier model successfully predicted wine types (Red/White) with perfect accuracy on the test set.\n",
    "\n",
    "### Key Results:\n",
    "- **Accuracy**: The model achieved an accuracy of **1.0000** on the test set, indicating that all predictions were correct.\n",
    "- **Precision, Recall, and F1-Score**: All metrics achieved **1.00** for both classes, indicating perfect prediction performance for both the False and True classes.\n",
    "\n",
    "### Conclusion:\n",
    "The model has demonstrated excellent performance in classifying wines into different types based on the given features. With an accuracy of 100% and perfect precision, recall, and F1-score, the model can be considered highly reliable. However, it is important to assess the dataset for possible imbalances or data leakage to ensure that this performance is legitimate and not artificially inflated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alcohol Content (ABV) Prediction using Support Vector Regression (SVR): Model Performance & Results - Task [091]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.0398\n",
      "Mean Squared Error (MSE): 0.0020\n",
      "Root Mean Squared Error (RMSE): 0.0449\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assume 'encoded_df' is the DataFrame after preprocessing\n",
    "\n",
    "# Step 1: Define the target variable and feature columns\n",
    "target_column = 'ABV'  # Predicting 'ABV' (Alcohol By Volume)\n",
    "\n",
    "# Selecting features (all columns except the target column)\n",
    "features = encoded_df.drop(columns=[target_column])  # Dropping the target column\n",
    "target = encoded_df[target_column]  # The target variable is 'ABV'\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Data preprocessing (handling categorical and numerical features)\n",
    "# One-hot encoding for categorical columns, standard scaling for numerical columns\n",
    "categorical_columns = features.select_dtypes(include=['object']).columns\n",
    "numerical_columns = features.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Step 4: Create an SVR pipeline (combine preprocessor with SVR model)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', SVR(kernel='linear'))\n",
    "])\n",
    "\n",
    "# Step 5: Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model's performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Manually calculate RMSE by taking the square root of MSE\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The Support Vector Regression (SVR) model was used to predict the alcohol content (ABV) of wines. The model achieved reasonable accuracy with low error metrics, making it a reliable approach for this regression task.\n",
    "\n",
    "### Key Results:\n",
    "- **Mean Absolute Error (MAE)**: The MAE is **0.0398**, indicating the average deviation of predicted values from actual values.\n",
    "- **Mean Squared Error (MSE)**: The MSE is **0.0020**, showing that the squared differences between the predicted and actual values are small.\n",
    "- **Root Mean Squared Error (RMSE)**: The RMSE is **0.0449**, indicating the typical magnitude of the model's prediction errors.\n",
    "\n",
    "### Conclusion:\n",
    "The SVR model performed well in predicting the alcohol content (ABV) of wines with low error values across the metrics. However, further improvements can be made with hyperparameter tuning, feature engineering, and cross-validation to enhance the accuracy of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
