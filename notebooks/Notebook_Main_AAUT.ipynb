{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização dataset - Task [001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ftfy import fix_text\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv file with pandas and read it into a dataframe\n",
    "df = pd.read_csv('../datasets/WineDataset.csv')\n",
    "df2 = pd.read_csv('../datasets/XWines_Full_100K_wines.csv')\n",
    "df3 = pd.read_csv('../datasets/merged_wine_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the information about the dataframe\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the information about the dataframe\n",
    "df2.info()\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the information about the dataframe\n",
    "df3.info()\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix text using ftfy\n",
    "# fix all the columns except when the column is a float\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object': \n",
    "        df[col] = df[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "# fix text using ftfy\n",
    "# fix all the columns except when the column is a float\n",
    "for col in df2.columns:\n",
    "    if df2[col].dtype == 'object': \n",
    "        df2[col] = df2[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all the unique values for each column except for the columns:'Title' 'Description', 'Country', 'Unit' 'Region' 'Appellation'\n",
    "for col in df.columns:\n",
    "    if col not in ['Title', 'Description', 'Country', 'Unit', 'Region', 'Appellation']:\n",
    "        print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df3.columns:\n",
    "    if col not in ['WineName', 'WineryName', 'Grape', 'Secondary Grape Varieties', 'Country', 'Region', 'Appellation', 'Style', 'Characteristics', 'Description']:\n",
    "        print(col, df3[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de dados\n",
    "- Remoção de valores nulos\n",
    "- Normalização de valores\n",
    "- Remoção de colunas desnecessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print wine where wineid 131027\n",
    "print(df2.loc[df2['WineID'] == 131027])\n",
    "\n",
    "#One-Hot Encoding for the column 'Type' 'Elaborate' 'Body', 'Acidity'\n",
    "\n",
    "one_hot_encoded_df = pd.get_dummies(df2, columns=['Type','Body','Acidity','Elaborate'], prefix=['Type','Body','Acidity','Elaborate'])\n",
    "\n",
    "# Binary Encoding for the column 'Country', 'RegionName', 'Grapes', 'Harmonize'\n",
    "\n",
    "encoder = BinaryEncoder(cols=['Grapes', 'Harmonize'], return_df=True)\n",
    "binary_encoded_df = encoder.fit_transform(df2)\n",
    "\n",
    "encoded_df = pd.concat([one_hot_encoded_df, binary_encoded_df], axis=1)\n",
    "\n",
    "# Normalize the 'ABV' column using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing the 'ABV' column\n",
    "encoded_df['ABV'] = scaler.fit_transform(encoded_df[['ABV']])\n",
    "\n",
    "\n",
    "encoded_df = encoded_df.drop(columns=df2.columns)\t\n",
    "encoded_df = encoded_df.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Dataset Preprocessing - Task [066]\n",
    "### Normalizing Harmonize and grouping it into broader categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dishes with their broader categories in the Harmonize column\n",
    "df2['Harmonize'] = df2['Harmonize'].apply(eval)\n",
    "dish_to_category = {\n",
    "    'Beef': 'Meat', 'Lamb': 'Meat', 'Pork': 'Meat', 'Veal': 'Meat', 'Game Meat': 'Meat',\n",
    "    'Duck': 'Meat', 'Ham': 'Meat', 'Cold Cuts': 'Meat', 'Cured Meat': 'Meat',\n",
    "    'Poultry': 'Poultry', 'Chicken': 'Poultry',\n",
    "    'Rich Fish': 'Fish & Seafood', 'Lean Fish': 'Fish & Seafood', 'Shellfish': 'Fish & Seafood',\n",
    "    'Seafood': 'Fish & Seafood', 'Sushi': 'Fish & Seafood', 'Sashimi': 'Fish & Seafood',\n",
    "    'Codfish': 'Fish & Seafood', 'Fish': 'Fish & Seafood', 'Grilled': 'Fish & Seafood',\n",
    "    'Soft Cheese': 'Cheese', 'Hard Cheese': 'Cheese', 'Blue Cheese': 'Cheese',\n",
    "    'Maturated Cheese': 'Cheese', 'Goat Cheese': 'Cheese', 'Mild Cheese': 'Cheese',\n",
    "    'Medium-cured Cheese': 'Cheese', 'Cheese': 'Cheese',\n",
    "    'Pasta': 'Pasta', 'Tagliatelle': 'Pasta', 'Lasagna': 'Pasta',\n",
    "    'Paella': 'Fish & Seafood', 'Pizza' : 'Pasta',\n",
    "    'Vegetarian': 'Vegetarian & Vegan', 'Mushrooms': 'Vegetarian & Vegan', 'Salad': 'Vegetarian & Vegan',\n",
    "    'Fruit': 'Vegetarian & Vegan', 'Tomato Dishes': 'Vegetarian & Vegan', 'Beans': 'Vegetarian & Vegan',\n",
    "    'Eggplant Parmigiana': 'Vegetarian & Vegan', 'Light Stews': 'Vegetarian & Vegan',\n",
    "    'Appetizer': 'Appetizers & Snacks', 'Snack': 'Appetizers & Snacks',\n",
    "    'Aperitif': 'Appetizers & Snacks', 'French Fries': 'Appetizers & Snacks', 'Baked Potato': 'Appetizers & Snacks',\n",
    "    'Cream': 'Appetizers & Snacks',\n",
    "    'Sweet Dessert': 'Desserts', 'Fruit Dessert': 'Desserts', 'Citric Dessert': 'Desserts',\n",
    "    'Cake': 'Desserts', 'Chocolate': 'Desserts', 'Cookies': 'Desserts',\n",
    "    'Chestnut': 'Desserts', 'Spiced Fruit Cake': 'Desserts', 'Dessert': 'Desserts',\n",
    "    'Soufflé': 'Desserts', 'Dried Fruits': 'Desserts',\n",
    "    'Spicy Food': 'Spicy Food', 'Curry Chicken': 'Spicy Food', 'Asian Food': 'Spicy Food', 'Yakissoba': 'Spicy Food',\n",
    "    'Barbecue': 'Meat', 'Roast': 'Meat'\n",
    "}\n",
    "\n",
    "columns = df2.columns\n",
    "new_harmonize = df2.copy()\n",
    "new_harmonize['Harmonize'] = df2['Harmonize'].apply(lambda x: list(set(dish_to_category.get(dish, dish) for dish in x)))\n",
    "\n",
    "# Expand the Harmonize column into multiple rows, one for each dish\n",
    "new_harmonize = new_harmonize.explode('Harmonize')\n",
    "\n",
    "# Reset the index for consistency and remove any rows with 'Risotto' because it has a number of insignificant occurrences\n",
    "new_harmonize.reset_index(drop=True, inplace=True)\n",
    "new_harmonize = new_harmonize[new_harmonize['Harmonize'].apply(lambda x: 'Risotto' not in x)]\n",
    "df2 = new_harmonize.copy()\n",
    "\n",
    "# Get the unique dishes\n",
    "unique_categories = df2['Harmonize'].unique()\n",
    "\n",
    "# One-hot encoding\n",
    "for dish in unique_categories:\n",
    "    new_harmonize[f'Harmonize_{dish}'] = new_harmonize['Harmonize'].apply(lambda x: x == dish)\n",
    "# Turn new_harmonize into a harmonize dataframe\n",
    "new_harmonize = new_harmonize.drop(columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding for the column 'Type' 'Elaborate' 'Body', 'Acidity'\n",
    "one_hot_encoded_df = pd.get_dummies(df2, columns=['Type', 'Elaborate', 'Body', 'Acidity'])\n",
    "\n",
    "# Binary Encoding for the column 'Grapes'\n",
    "encoder = BinaryEncoder(cols=['Grapes'], return_df=True)\n",
    "binary_encoded_df = encoder.fit_transform(df2)\n",
    "\n",
    "encoded_df = one_hot_encoded_df.copy()\n",
    "\n",
    "# Maximum ABV value\n",
    "print(encoded_df['ABV'].min())\n",
    "print(encoded_df['ABV'].max())\n",
    "\n",
    "# get the row where the abv is min\n",
    "print(encoded_df[encoded_df['ABV'] == encoded_df['ABV'].min()])\n",
    "\n",
    "\n",
    "# Normalizing the 'ABV' column\n",
    "scaler = MinMaxScaler()\n",
    "encoded_df['ABV'] = scaler.fit_transform(encoded_df[['ABV']])\n",
    "\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "encoded_df = encoded_df.drop(columns=['Country', 'RegionName', 'Code', 'WineName', 'WineID', 'Vintages', 'Website', 'WineryID', 'WineryName', 'RegionID','Grapes','Harmonize'])\n",
    "encoded_df = encoded_df.dropna()\n",
    "# add new_harmonize to the encoded_df\n",
    "encoded_df = pd.concat([encoded_df, new_harmonize], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR\n",
    "numeric_df = encoded_df['ABV']\n",
    "q1 = numeric_df.quantile(0.25)\n",
    "q3 = numeric_df.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=numeric_df, showmeans=True, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the resulting boxplot, we observe that some values fall outside the ranges but are still relevant, as 0% alcohol wines, including dealcoholized varieties, remain within the wine category. These options retain the essence of traditional wines without alcohol. Additionally, beverages like firewater, with higher alcohol content, can also bring value to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix without the Elaborate columns to reduce the size of the heatmap\n",
    "elaborate_columns = encoded_df.columns[encoded_df.columns.str.startswith('Elaborate_')]\n",
    "matrix_df = encoded_df.drop(columns=elaborate_columns)\n",
    "correlation_matrix = matrix_df.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True, \n",
    "    fmt=\".2f\", \n",
    "    cmap=\"coolwarm\", \n",
    "    cbar=True, \n",
    "    annot_kws={\"size\": 10}\n",
    ")\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the matrix, we observe that it is relatively ‘cold,’ meaning it exhibits a low correlation index overall. Despite the generally low correlations between features, certain specific relationships do stand out. For instance, some dishes in the ‘Harmonize’ category show a notable correlation with particular wines, while certain body characteristics correlate with the alcohol by volume (ABV) and wine types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "harmonize_columns = [col for col in encoded_df.columns if col.startswith('Harmonize_')]\n",
    "\n",
    "# Loop through each 'harmonize_' column and perform PCA\n",
    "for label_col in harmonize_columns:\n",
    "    print(f\"Generating PCA plot for label column: {label_col}\")\n",
    "\n",
    "    features = encoded_df.drop(columns=[label_col])\n",
    "    labels = encoded_df[label_col].values\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    df_pca = pca.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_labels = np.unique(labels)\n",
    "    for label in unique_labels:\n",
    "        plt.scatter(\n",
    "            df_pca[labels == label, 0], \n",
    "            df_pca[labels == label, 1], \n",
    "            label=f'Classe {label}'\n",
    "        )\n",
    "\n",
    "    plt.title(f'PCA - Column: {label_col}')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying PCA to identify patterns and relationships among the different categories in the ‘Harmonize’ column, we encountered inconclusive results. The resulting plots showed the various categories exhibiting similar patterns, with data points widely scattered across the graphical space rather than concentrated in specific zones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🍷 Wine Type Prediction using Random Forest Classifier: Model Performance & Results - Task [089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     31066\n",
      "        True       1.00      1.00      1.00     24563\n",
      "\n",
      "    accuracy                           1.00     55629\n",
      "   macro avg       1.00      1.00      1.00     55629\n",
      "weighted avg       1.00      1.00      1.00     55629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assume 'encoded_df' is the DataFrame you have after preprocessing\n",
    "\n",
    "# Step 1: Define the target variable and feature columns\n",
    "target_column = 'Type_Red'  # Choosing 'Type_Red' as the target column (Wine Type - Red)\n",
    "\n",
    "# Selecting features (all columns except the target column)\n",
    "features = encoded_df.drop(columns=[target_column])  # Dropping the target column\n",
    "target = encoded_df[target_column]  # The target variable is 'Type_Red'\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Data preprocessing (handling categorical and numerical features)\n",
    "# We'll use one-hot encoding for categorical columns and standard scaling for numerical columns\n",
    "categorical_columns = features.select_dtypes(include=['object']).columns  # Identify categorical columns\n",
    "numerical_columns = features.select_dtypes(exclude=['object']).columns  # Identify numerical columns\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),  # StandardScaler for numerical columns\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # OneHotEncoder for categorical columns\n",
    "    ])\n",
    "\n",
    "# Step 4: Create a Random Forest pipeline (combine preprocessor with model)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Apply preprocessing first\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Train a Random Forest model\n",
    "])\n",
    "\n",
    "# Step 5: Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "\n",
    "# Save model for future use (optional)\n",
    "# from joblib import dump\n",
    "# dump(pipeline, 'random_forest_wine_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance on Wine Type Prediction\n",
    "\n",
    "The model we built using **Random Forest Classifier** was trained to predict the wine type based on various features, including wine attributes like alcohol content (`ABV`), body (`Body_*`), acidity (`Acidity_*`), and blend types (`Elaborate_Assemblage/*`), among others.\n",
    "\n",
    "## Key Results:\n",
    "- **Accuracy**: The model achieved an accuracy of **1.0000** on the test set, meaning it correctly predicted the wine type for all the test samples.\n",
    "\n",
    "### Classification Report:\n",
    "- **Precision**: The precision for both classes (`False` and `True`) is **1.00**, indicating that all positive predictions made by the model were correct.\n",
    "- **Recall**: The recall for both classes is also **1.00**, meaning the model correctly identified all actual positives.\n",
    "- **F1-Score**: The F1-score is **1.00** for both classes, indicating that the model has achieved perfect balance between precision and recall.\n",
    "\n",
    "The **support** values (31066 for `False` and 24563 for `True`) represent the number of samples for each class in the test set.\n",
    "\n",
    "## Conclusion:\n",
    "The Random Forest model has performed **perfectly** in classifying wines into different types based on the provided features. With an accuracy of **100%** and perfect precision, recall, and F1-score, the model has demonstrated an outstanding ability to predict the wine type accurately. However, given the perfect results, it's worth checking if the data might be imbalanced or if there are any data leakage issues, as this level of performance is uncommon in real-world datasets. If the data is balanced and without leakage, this model can be considered highly reliable for wine classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
