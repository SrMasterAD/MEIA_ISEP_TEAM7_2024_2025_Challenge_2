{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ftfy import fix_text\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5723723e80699a4",
   "metadata": {},
   "source": [
    "# open the csv file with pandas and read it into a dataframe\n",
    "df = pd.read_csv('../datasets/WineDataset.csv')\n",
    "df2 = pd.read_csv('../datasets/XWines_Full_100K_wines.csv')\n",
    "df3 = pd.read_csv('../datasets/merged_wine_dataset.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dda0a233359febd7",
   "metadata": {},
   "source": [
    "# fix text using ftfy\n",
    "# fix all the columns except when the column is a float\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "# fix text using ftfy\n",
    "# fix all the columns except when the column is a float\n",
    "for col in df2.columns:\n",
    "    if df2[col].dtype == 'object':\n",
    "        df2[col] = df2[col].apply(lambda x: fix_text(x) if isinstance(x, str) else x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a78786409633681d",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c18673122e5545d",
   "metadata": {},
   "source": [
    "# Print wine where wineid 131027\n",
    "print(df2.loc[df2['WineID'] == 131027])\n",
    "\n",
    "#One-Hot Encoding for the column 'Type' 'Elaborate' 'Body', 'Acidity'\n",
    "\n",
    "one_hot_encoded_df = pd.get_dummies(df2, columns=['Type','Body','Acidity','Elaborate'], prefix=['Type','Body','Acidity','Elaborate'])\n",
    "\n",
    "# Binary Encoding for the column 'Country', 'RegionName', 'Grapes', 'Harmonize'\n",
    "\n",
    "encoder = BinaryEncoder(cols=['Grapes', 'Harmonize'], return_df=True)\n",
    "binary_encoded_df = encoder.fit_transform(df2)\n",
    "\n",
    "encoded_df = pd.concat([one_hot_encoded_df, binary_encoded_df], axis=1)\n",
    "\n",
    "# Normalize the 'ABV' column using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing the 'ABV' column\n",
    "encoded_df['ABV'] = scaler.fit_transform(encoded_df[['ABV']])\n",
    "\n",
    "\n",
    "encoded_df = encoded_df.drop(columns=df2.columns)\n",
    "encoded_df = encoded_df.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(encoded_df)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f80c86311bf89fb5",
   "metadata": {},
   "source": [
    "### Normalization dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "32ee4fa816765531",
   "metadata": {},
   "source": [
    "#Count how many grapes in the column grapes are unique grapes are in a array\n",
    "grapes = df2['Grapes'].str.split(',').explode().unique()\n",
    "\n",
    "#Remove every \"]\"\" and \"[\" and \",\" and \"'\" and remove spaces if they are in the first character or the last character\n",
    "grapes = [grape.replace(']', '').replace('[', '').replace(',', '').replace(\"'\", '').strip() for grape in grapes]\n",
    "\n",
    "grapes2 = ['Tempranillo', 'Chardonnay', 'Sauvignon Blanc', 'Pinot Noir', 'Glera', 'Chenin Blanc', 'Castelão ', 'Malagousia', 'Cinsault', 'Grenache', 'Shiraz', 'Cabernet Sauvignon', 'Bacchus', 'Viognier', 'Pinot Grigio', 'Garnacha', 'Malbec', 'Cortese', 'Merlot', 'Melon De Bourgogne', 'Carménère', 'Zinfandel', 'Syrah', 'Marsanne', 'Gruner Veltliner', 'Corvina', 'Greco', 'Macabeo', 'Gamay', 'Loureiro', 'Riesling', 'Alvarinho', 'Mourvèdre', 'Cabernet Franc', 'Vespaiola', 'Picpoul', 'Vermentino', 'Sangiovese', 'Pinot Meunier', 'Verdejo', 'Primitivo', 'Pinotage', 'Alicante Bouschet', 'Garganega', 'Godello', 'Carignan', 'Grenache Blanc', 'Aligoté', 'Siegerrebe', 'Touriga Nacional', 'Albarino', 'Nerello Mascalese', \"Nero D'Avola\", 'Turbiana', 'Pinot Gris', 'Airen', 'Trincadeira', 'Tinta Roriz', 'Xinomavro', 'Agiorgitiko', 'Pais', 'Gewürztraminer', 'Mencia', 'Verdicchio', 'Fiano', 'Rondinella', 'Mauzac', 'Nebbiolo', 'Lambrusco Grasparossa', 'Pecorino', 'Negroamaro', 'Fernão Pires', 'Feteasca Alba', 'Zwieigelt', 'Grillo', 'Tinta Barroca', 'Furmint', 'Touriga Franca', 'Pedro Ximénez', 'Palomino', 'Viura', 'Montepulciano', 'Barbera', 'Malvasia', 'Arinto', 'Colombard', 'Sémillon', 'Jacquere', 'Pinot Blanc', 'Rkatsiteli', 'Syrah-Shiraz', 'Torrontes', 'Sauvignon Gris', 'Assyrtiko', 'Moscato', 'Rolle', 'Huxelrebe', 'Xarel-Lo', 'Niellucciu', 'Saperavi', 'Rara Neagra', 'Non Varietal', 'Muscat', 'Monastrell', 'Dolcetto', 'Black Muscat', 'Nerello', 'Roussanne', 'Tibouren', 'Grolleau', 'Inzolia', 'Falanghina', 'Aglianico']\n",
    "\n",
    "# Create a new array of grapes where both of the grapes match\n",
    "grapes = list(set(grapes) & set(grapes2))\n",
    "print(grapes)\n",
    "\n",
    "df2['Grapes'] = df2['Grapes'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "df2['Grapes'] = df2['Grapes'].apply(\n",
    "    lambda x: [grape for grape in x if grape in grapes]\n",
    ")\n",
    "\n",
    "df2 = df2[df2['Grapes'].str.len() > 0]\n",
    "\n",
    "# Retain all grape types (multi-label setting)\n",
    "# One-hot encoding for multi-label classification\n",
    "grape_set = sorted(list(set(grapes2)))  # Ensure consistent order for multi-hot encoding\n",
    "multi_hot_encoded_grapes = pd.DataFrame(\n",
    "    {f'Grapes_{grape}': df2['Grapes'].apply(lambda x: 1 if grape in x else 0) for grape in grape_set}\n",
    ")\n",
    "\n",
    "# Concatenate the new columns with the original DataFrame\n",
    "encoded_df = pd.concat([encoded_df, multi_hot_encoded_grapes], axis=1)\n",
    "\n",
    "# Replace dishes with their broader categories in the Harmonize column\n",
    "df2['Harmonize'] = df2['Harmonize'].apply(eval)\n",
    "dish_to_category = {\n",
    "    'Beef': 'Meat', 'Lamb': 'Meat', 'Pork': 'Meat', 'Veal': 'Meat', 'Game Meat': 'Meat',\n",
    "    'Duck': 'Meat', 'Ham': 'Meat', 'Cold Cuts': 'Meat', 'Cured Meat': 'Meat',\n",
    "    'Poultry': 'Poultry', 'Chicken': 'Poultry',\n",
    "    'Rich Fish': 'Fish & Seafood', 'Lean Fish': 'Fish & Seafood', 'Shellfish': 'Fish & Seafood',\n",
    "    'Seafood': 'Fish & Seafood', 'Sushi': 'Fish & Seafood', 'Sashimi': 'Fish & Seafood',\n",
    "    'Codfish': 'Fish & Seafood', 'Fish': 'Fish & Seafood', 'Grilled': 'Fish & Seafood',\n",
    "    'Soft Cheese': 'Cheese', 'Hard Cheese': 'Cheese', 'Blue Cheese': 'Cheese',\n",
    "    'Maturated Cheese': 'Cheese', 'Goat Cheese': 'Cheese', 'Mild Cheese': 'Cheese',\n",
    "    'Medium-cured Cheese': 'Cheese', 'Cheese': 'Cheese',\n",
    "    'Pasta': 'Pasta', 'Tagliatelle': 'Pasta', 'Lasagna': 'Pasta',\n",
    "    'Paella': 'Fish & Seafood', 'Pizza' : 'Pasta',\n",
    "    'Vegetarian': 'Vegetarian & Vegan', 'Mushrooms': 'Vegetarian & Vegan', 'Salad': 'Vegetarian & Vegan',\n",
    "    'Fruit': 'Vegetarian & Vegan', 'Tomato Dishes': 'Vegetarian & Vegan', 'Beans': 'Vegetarian & Vegan',\n",
    "    'Eggplant Parmigiana': 'Vegetarian & Vegan', 'Light Stews': 'Vegetarian & Vegan',\n",
    "    'Appetizer': 'Appetizers & Snacks', 'Snack': 'Appetizers & Snacks',\n",
    "    'Aperitif': 'Appetizers & Snacks', 'French Fries': 'Appetizers & Snacks', 'Baked Potato': 'Appetizers & Snacks',\n",
    "    'Cream': 'Appetizers & Snacks',\n",
    "    'Sweet Dessert': 'Desserts', 'Fruit Dessert': 'Desserts', 'Citric Dessert': 'Desserts',\n",
    "    'Cake': 'Desserts', 'Chocolate': 'Desserts', 'Cookies': 'Desserts',\n",
    "    'Chestnut': 'Desserts', 'Spiced Fruit Cake': 'Desserts', 'Dessert': 'Desserts',\n",
    "    'Soufflé': 'Desserts', 'Dried Fruits': 'Desserts',\n",
    "    'Spicy Food': 'Spicy Food', 'Curry Chicken': 'Spicy Food', 'Asian Food': 'Spicy Food', 'Yakissoba': 'Spicy Food',\n",
    "    'Barbecue': 'Meat', 'Roast': 'Meat'\n",
    "}\n",
    "\n",
    "columns = df2.columns\n",
    "new_harmonize = df2.copy()\n",
    "new_harmonize['Harmonize'] = df2['Harmonize'].apply(lambda x: list(set(dish_to_category.get(dish, dish) for dish in x)))\n",
    "\n",
    "# Expand the Harmonize column into multiple rows, one for each dish\n",
    "new_harmonize = new_harmonize.explode('Harmonize')\n",
    "\n",
    "# Reset the index for consistency and remove any rows with 'Risotto' because it has a number of insignificant occurrences\n",
    "new_harmonize.reset_index(drop=True, inplace=True)\n",
    "new_harmonize = new_harmonize[new_harmonize['Harmonize'].apply(lambda x: 'Risotto' not in x)]\n",
    "df2 = new_harmonize.copy()\n",
    "\n",
    "# Get the unique dishes\n",
    "unique_categories = df2['Harmonize'].unique()\n",
    "\n",
    "# One-hot encoding\n",
    "for dish in unique_categories:\n",
    "    new_harmonize[f'Harmonize_{dish}'] = new_harmonize['Harmonize'].apply(lambda x: x == dish)\n",
    "# Turn new_harmonize into a harmonize dataframe\n",
    "new_harmonize = new_harmonize.drop(columns=columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df653b8694bd366a",
   "metadata": {},
   "source": [
    "**Rest of columns**"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0b276c184536a71",
   "metadata": {},
   "source": [
    "# One-Hot Encoding for 'Type', 'Elaborate', 'Body', 'Acidity' (single-label columns)\n",
    "one_hot_encoded_df = pd.get_dummies(df2, columns=['Type', 'Elaborate', 'Body', 'Acidity'])\n",
    "\n",
    "# Multi-Hot Encoding for 'Grapes' (multi-label column)\n",
    "multi_hot_encoded_grapes = pd.DataFrame(\n",
    "    {f'Grapes_{grape}': df2['Grapes'].apply(lambda x: 1 if grape in x else 0) for grape in grapes2}\n",
    ")\n",
    "\n",
    "# Concatenate multi-hot encoded grapes with the one-hot encoded DataFrame\n",
    "encoded_df = pd.concat([one_hot_encoded_df, multi_hot_encoded_grapes], axis=1)\n",
    "\n",
    "# Maximum ABV value\n",
    "print(encoded_df['ABV'].min())\n",
    "print(encoded_df['ABV'].max())\n",
    "\n",
    "# Normalizing the 'ABV' column\n",
    "scaler = MinMaxScaler()\n",
    "encoded_df['ABV'] = scaler.fit_transform(encoded_df[['ABV']])\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "encoded_df = encoded_df.drop(columns=['Country', 'RegionName', 'Code', 'WineName', 'WineID', 'Vintages', 'Website', 'WineryID', 'WineryName', 'RegionID','Harmonize'])\n",
    "encoded_df = encoded_df.dropna()\n",
    "print(encoded_df.columns)\n",
    "# add new_harmonize to the encoded_df\n",
    "encoded_df = pd.concat([encoded_df, new_harmonize], axis=1)\n",
    "encoded_df = encoded_df.drop(columns=['Grapes'])\n",
    "encoded_df = encoded_df.astype(bool)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove grape columns with zero instances\n",
    "grape_columns = [col for col in encoded_df.columns if col.startswith('Grapes_')]\n",
    "harmonize_columns = [col for col in encoded_df.columns if col.startswith('Harmonize_')]\n",
    "\n",
    "grape_counts = encoded_df[grape_columns].sum(axis=0)\n",
    "non_zero_grape_columns = grape_counts[grape_counts > 0].index\n",
    "encoded_df = encoded_df[non_zero_grape_columns.union(harmonize_columns)]  # Keep only non-zero grape columns and harmonize columns\n"
   ],
   "id": "de99cf591efdbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Calculate the total count for each grape column\n",
    "grape_counts = encoded_df.filter(like='Grapes_').sum(axis=0)  # Only include valid grape columns\n",
    "\n",
    "# Step 2: Set a minimum threshold (e.g., median count of all grapes)\n",
    "min_threshold = grape_counts.median()\n",
    "\n",
    "# Step 3: Identify underrepresented grape columns\n",
    "underrepresented_grapes = grape_counts[grape_counts < min_threshold].index.tolist()\n",
    "\n",
    "# Step 4: Filter underrepresented_grapes to only include existing columns in encoded_df\n",
    "underrepresented_grapes = [col for col in underrepresented_grapes if col in encoded_df.columns]\n",
    "\n",
    "# Step 5: Oversample rows containing underrepresented grapes\n",
    "oversampled_rows = encoded_df[encoded_df[underrepresented_grapes].sum(axis=1) > 0]\n",
    "\n",
    "# Step 6: Randomly sample additional rows to balance the dataset\n",
    "additional_samples = oversampled_rows.sample(n=int(len(encoded_df) * 0.5), replace=True, random_state=42)\n",
    "\n",
    "# Step 7: Concatenate the oversampled rows with the original dataset\n",
    "balanced_encoded_df = pd.concat([encoded_df, additional_samples], axis=0).reset_index(drop=True)\n"
   ],
   "id": "8aa8e87297f5eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c31eed4736ab8038",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c3069316c2229",
   "metadata": {},
   "source": [
    "**imports and data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f3ac9dd49105f6d",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "harmonize_columns = [col for col in balanced_encoded_df.columns if col.startswith('Harmonize_')]\n",
    "harmonize_mapping = {i: col.replace(\"Harmonize_\", \"\") for i, col in enumerate(harmonize_columns)}\n",
    "# Step 2: Feature and Target Preparation\n",
    "type_columns = [col for col in encoded_df.columns if col.startswith('Type_')]\n",
    "grape_columns = [col for col in balanced_encoded_df.columns if col.startswith('Grapes_')]\n",
    "\n",
    "features = balanced_encoded_df[harmonize_columns]# Targets are harmonize columns\n",
    "labels = balanced_encoded_df[grape_columns]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1993feeb5ebeef3d",
   "metadata": {},
   "source": [
    "**multi-label validation**"
   ]
  },
  {
   "cell_type": "code",
   "id": "35553a6ce645b386",
   "metadata": {},
   "source": [
    "# Count the occurrences of each grape variety in the labels\n",
    "label_counts = balanced_encoded_df[grape_columns].sum().sort_values(ascending=False)\n",
    "\n",
    "# Display the counts\n",
    "print(\"Label counts for each grape variety:\")\n",
    "print(label_counts)\n",
    "\n",
    "# Plot the label distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title(\"Label Distribution of Grape Varieties\")\n",
    "plt.xlabel(\"Grape Varieties\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d54f26a4aff63231",
   "metadata": {},
   "source": [
    "# Convert each row of grape labels into a tuple and count unique combinations\n",
    "unique_combinations = encoded_df[grape_columns].apply(tuple, axis=1).nunique()\n",
    "\n",
    "print(f\"Number of unique label combinations: {unique_combinations}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "963b73dfb5907adb",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute correlation matrix for grape varieties\n",
    "correlation_matrix = encoded_df[grape_columns].corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap of Grape Varieties\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dfd4acb21cfc494b",
   "metadata": {},
   "source": [
    "**The training model without hyper-parameters tuning:**"
   ]
  },
  {
   "cell_type": "code",
   "id": "effe30b78bd084cb",
   "metadata": {},
   "source": [
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Neural Network Setup\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Define input shape explicitly\n",
    "    Dense(units=64, activation='relu'),  # Hidden layer\n",
    "    Dense(units=y_train.shape[1], activation='sigmoid')  # Output layer with sigmoid for multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 5: Visualize Training Progress\n",
    "def plot_training_progress(history, metric: str, title: str):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history[metric], label=f'Training {metric.capitalize()}')\n",
    "    plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')\n",
    "    plt.title(f'Model {title}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Accuracy plot\n",
    "plot_training_progress(history, metric='accuracy', title='Accuracy')\n",
    "\n",
    "# Loss plot\n",
    "plot_training_progress(history, metric='loss', title='Loss')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "957ee09f23ca0c9b",
   "metadata": {},
   "source": [
    "**With hyper-parameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "id": "487a4f2314c135cc",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "# Step2: Enable eager execution to ensure compatibility with numpy() calls\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_and_train_model(optimizer, batch_size, epochs):\n",
    "    clear_session()  # Clear backend session to reset model state\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Define input shape explicitly\n",
    "        Dense(units=y_train.shape[1], activation='softmax')  # Single-layer with softmax\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    # Return accuracy and training history for later visualization\n",
    "    return accuracy * 100, history\n",
    "\n",
    "# Hyperparameter grid\n",
    "batch_sizes = [32]\n",
    "epochs_list = [10, 20]\n",
    "\n",
    "def tune_optimizer(optimizer_class):\n",
    "    global best_accuracy, best_params, history\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochs_list:\n",
    "            optimizer = optimizer_class(learning_rate=0.001)  # Create a new optimizer instance\n",
    "            print(f\"Training with optimizer={optimizer.__class__.__name__}, batch_size={batch_size}, epochs={epochs}\")\n",
    "            accuracy, history = build_and_train_model(optimizer, batch_size, epochs)\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    'optimizer': optimizer.__class__.__name__,\n",
    "                    'batch_size': batch_size,\n",
    "                    'epochs': epochs\n",
    "                }\n",
    "\n",
    "    print(\"Best Hyperparameters for Optimizer:\")\n",
    "    print(f\"Optimizer: {best_params['optimizer']}\")\n",
    "    print(f\"Batch Size: {best_params['batch_size']}\")\n",
    "    print(f\"Epochs: {best_params['epochs']}\")\n",
    "    print(f\"Best Accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "    # Visualize training progress for the best combination\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Best Accuracy - Optimizer: {best_params[\"optimizer\"]}, Batch Size: {best_params[\"batch_size\"]}, Epochs: {best_params[\"epochs\"]}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Best Loss - Optimizer: {best_params[\"optimizer\"]}, Batch Size: {best_params[\"batch_size\"]}, Epochs: {best_params[\"epochs\"]}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Tuning for Adam optimizer:\")\n",
    "tune_optimizer(Adam)\n",
    "\n",
    "print(\"Tuning for SGD optimizer:\")\n",
    "tune_optimizer(SGD)\n",
    "\n",
    "print(\"Tuning for RMSprop optimizer:\")\n",
    "tune_optimizer(RMSprop)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Best Loss - Optimizer: {best_params[\"optimizer\"]}, Batch Size: {best_params[\"batch_size\"]}, Epochs: {best_params[\"epochs\"]}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc30b22fab841226",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation\n",
    "**Predictions as classification for a single meal**"
   ]
  },
  {
   "cell_type": "code",
   "id": "3adf6c38c0a9d4bf",
   "metadata": {},
   "source": [
    "# Function to predict the best grape for a given harmonize label\n",
    "def predict_best_grape(harmonize_label, data_frame, neural_model):\n",
    "    harmonize_col = f\"Harmonize_{harmonize_label}\"\n",
    "    if harmonize_col not in data_frame.columns:\n",
    "        return {\"Error\": f\"Harmonize label '{harmonize_label}' not found in dataset.\"}\n",
    "\n",
    "    # Create an input vector for the given harmonize label\n",
    "    input_vector = pd.Series(0, index=data_frame.columns)  # Initialize all values to zero\n",
    "    input_vector[harmonize_col] = 1  # Set the given harmonize column to 1\n",
    "\n",
    "    # Select only relevant input features (harmonize columns)\n",
    "    input_vector = input_vector[harmonize_columns].values.reshape(1, -1)  # Reshape for prediction\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction = neural_model.predict(input_vector)\n",
    "\n",
    "    # Get the best grape based on the highest prediction value\n",
    "    predicted_grape_index = np.argmax(prediction[0])\n",
    "    predicted_grape = grape_columns[predicted_grape_index].replace(\"Grapes_\", \"\")\n",
    "\n",
    "    return {\"Harmonize\": harmonize_label, \"Best Grape\": predicted_grape}\n",
    "\n",
    "# Example usage\n",
    "harmonize_label = \"Meat\"  # Replace with the desired harmonize label\n",
    "result = predict_best_grape(harmonize_label, encoded_df, model)\n",
    "print(f\"Prediction for Harmonize '{harmonize_label}': Best Grape: {result['Best Grape']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80f7236c3fc7bb9d",
   "metadata": {},
   "source": [
    "# Function to predict the best wine type for a given harmonize label\n",
    "def predict_best_wine(harmonize_label, data_frame, neural_model):\n",
    "    harmonize_col = f\"Harmonize_{harmonize_label}\"\n",
    "    if harmonize_col not in data_frame.columns:\n",
    "        return {\"Error\": f\"Harmonize label '{harmonize_label}' not found in dataset.\"}\n",
    "\n",
    "    # Create an input vector for the given harmonize label\n",
    "    input_vector = pd.Series(0, index=data_frame.columns)  # Initialize all values to zero\n",
    "    input_vector[harmonize_col] = 1  # Set the given harmonize column to 1\n",
    "\n",
    "    # Select only relevant input features (harmonize columns)\n",
    "    input_vector = input_vector[harmonize_columns].values.reshape(1, -1)  # Reshape for prediction\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction = neural_model.predict(input_vector)\n",
    "\n",
    "    # Get the best wine type based on the highest prediction value\n",
    "    predicted_wine_index = np.argmax(prediction[0])\n",
    "    predicted_wine = type_columns[predicted_wine_index].replace(\"Type_\", \"\")\n",
    "\n",
    "    return {\"Harmonize\": harmonize_label, \"Best Wine Type\": predicted_wine}\n",
    "\n",
    "# Example usage\n",
    "harmonize_label = \"Meat\"  # Replace with the desired harmonize label\n",
    "result = predict_best_wine(harmonize_label, encoded_df, model)\n",
    "print(f\"Prediction for Harmonize '{harmonize_label}': Best Wine Type: {result['Best Wine Type']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fc5cf44b6e98f0c",
   "metadata": {},
   "source": [
    "### Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763ec1983c11243",
   "metadata": {},
   "source": [
    "ROC Curve: Plots true positive rate vs. false positive rate.\n",
    "AUC: Measures the ability of the model to distinguish between classes."
   ]
  },
  {
   "cell_type": "code",
   "id": "c4e6692a238eac73",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Determine whether the model is trained for grapes or wine types\n",
    "if list(labels.columns) == grape_columns:\n",
    "    target_columns = grape_columns\n",
    "    title = 'ROC Curve for Grapes'\n",
    "elif list(labels.columns) == type_columns:\n",
    "    target_columns = type_columns\n",
    "    title = 'ROC Curve for Wine Types'\n",
    "else:\n",
    "    raise ValueError(\"Unknown label set. Ensure labels are either grape_columns or type_columns.\")\n",
    "\n",
    "# Calculate and plot ROC-AUC for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, class_name in enumerate(target_columns):\n",
    "    y_true = y_test.iloc[:, i]  # Extract true labels for the class\n",
    "    y_pred = predictions[:, i]  # Extract predicted probabilities for the class\n",
    "\n",
    "    # Check if the class has more than one unique value to avoid errors\n",
    "    if len(np.unique(y_true)) > 1:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        auc_score = roc_auc_score(y_true, y_pred)\n",
    "        plt.plot(fpr, tpr, label=f'{class_name.replace(\"Type_\", \"\").replace(\"Grapes_\", \"\")} (AUC: {auc_score:.2f})')\n",
    "    else:\n",
    "        print(f\"Skipping ROC-AUC for class '{class_name}' due to lack of variation in y_test.\")\n",
    "\n",
    "# Plot formatting\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for reference\n",
    "plt.title(title)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ace25fe82ac71488",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "Provides a detailed breakdown of true positives, true negatives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "id": "569ef6d2cd1fc92",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the labels (columns) are correctly identified\n",
    "if list(labels.columns) == grape_columns:\n",
    "    target_columns = grape_columns\n",
    "    title = \"Confusion Matrix for Grapes\"\n",
    "elif list(labels.columns) == type_columns:\n",
    "    target_columns = type_columns\n",
    "    title = \"Confusion Matrix for Wine Types\"\n",
    "else:\n",
    "    raise ValueError(\"Unknown label set. Ensure labels are either grape_columns or type_columns.\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "y_true_binary = y_test.values  # True binary labels\n",
    "y_pred_binary = (model.predict(X_test) > 0.5).astype(int)  # Predicted binary labels\n",
    "\n",
    "# Loop through each label to generate individual confusion matrices\n",
    "for i, class_name in enumerate(target_columns):\n",
    "    # Confusion matrix for the current label\n",
    "    cm = confusion_matrix(y_true_binary[:, i], y_pred_binary[:, i])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not \" + class_name, class_name])\n",
    "    disp.plot(cmap='viridis', xticks_rotation='vertical')\n",
    "    plt.title(f\"Confusion Matrix for {class_name.replace('Grapes_', '').replace('Type_', '')}\")\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3dd4935624e9c86c",
   "metadata": {},
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "# Convert predictions to binary classes using a threshold of 0.5\n",
    "predicted_classes = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Calculate the number of correct predictions (element-wise comparison)\n",
    "correct_predictions = np.sum((predicted_classes == y_test.values).all(axis=1))\n",
    "total_predictions = y_test.shape[0]\n",
    "\n",
    "# Baseline random accuracy (assumes equal probability for each class)\n",
    "if labels.equals(encoded_df[grape_columns]):\n",
    "    task_name = \"Grapes\"\n",
    "    random_accuracy = (1 / 2) ** len(grape_columns)\n",
    "elif labels.equals(encoded_df[type_columns]):\n",
    "    task_name = \"Wine Types\"\n",
    "    random_accuracy = (1 / 2) ** len(type_columns)\n",
    "else:\n",
    "    raise ValueError(\"Unknown label set. Ensure labels are either grape_columns or type_columns.\")\n",
    "\n",
    "# Perform the binomial test\n",
    "binom_test_result = binomtest(correct_predictions, total_predictions, random_accuracy)\n",
    "p_value = binom_test_result.pvalue\n",
    "\n",
    "# Output the result\n",
    "print(f\"Model Accuracy for {task_name}: {correct_predictions / total_predictions:.4f}, P-Value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"Model predictions for {task_name} are significantly better than random guessing.\")\n",
    "else:\n",
    "    print(f\"Model predictions for {task_name} are not significantly better than random guessing.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
